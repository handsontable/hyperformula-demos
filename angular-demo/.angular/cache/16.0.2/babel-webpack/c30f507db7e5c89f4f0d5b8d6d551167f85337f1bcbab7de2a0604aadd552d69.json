{"ast":null,"code":"var __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n    return extendStatics(d, b);\n  };\n  return function (d, b) {\n    extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\nimport { BaseRegExpVisitor } from \"regexp-to-ast\";\nimport { Lexer, LexerDefinitionErrorType } from \"./lexer_public\";\nimport { compact, contains, defaults, difference, filter, find, first, flatten, forEach, has, indexOf, isArray, isEmpty, isFunction, isRegExp, isString, isUndefined, keys, map, mapValues, packArray, PRINT_ERROR, reduce, reject } from \"../utils/utils\";\nimport { canMatchCharCode, failedOptimizationPrefixMsg, getOptimizedStartCodesIndices } from \"./reg_exp\";\nimport { getRegExpAst } from \"./reg_exp_parser\";\nvar PATTERN = \"PATTERN\";\nexport var DEFAULT_MODE = \"defaultMode\";\nexport var MODES = \"modes\";\nexport var SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\nexport function disableSticky() {\n  SUPPORT_STICKY = false;\n}\nexport function enableSticky() {\n  SUPPORT_STICKY = true;\n}\nexport function analyzeTokenTypes(tokenTypes, options) {\n  options = defaults(options, {\n    useSticky: SUPPORT_STICKY,\n    debug: false,\n    safeMode: false,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: function (msg, action) {\n      return action();\n    }\n  });\n  var tracer = options.tracer;\n  tracer(\"initCharCodeToOptimizedIndexMap\", function () {\n    initCharCodeToOptimizedIndexMap();\n  });\n  var onlyRelevantTypes;\n  tracer(\"Reject Lexer.NA\", function () {\n    onlyRelevantTypes = reject(tokenTypes, function (currType) {\n      return currType[PATTERN] === Lexer.NA;\n    });\n  });\n  var hasCustom = false;\n  var allTransformedPatterns;\n  tracer(\"Transform Patterns\", function () {\n    hasCustom = false;\n    allTransformedPatterns = map(onlyRelevantTypes, function (currType) {\n      var currPattern = currType[PATTERN];\n      /* istanbul ignore else */\n      if (isRegExp(currPattern)) {\n        var regExpSource = currPattern.source;\n        if (regExpSource.length === 1 &&\n        // only these regExp meta characters which can appear in a length one regExp\n        regExpSource !== \"^\" && regExpSource !== \"$\" && regExpSource !== \".\") {\n          return regExpSource;\n        } else if (regExpSource.length === 2 && regExpSource[0] === \"\\\\\" &&\n        // not a meta character\n        !contains([\"d\", \"D\", \"s\", \"S\", \"t\", \"r\", \"n\", \"t\", \"0\", \"c\", \"b\", \"B\", \"f\", \"v\", \"w\", \"W\"], regExpSource[1])) {\n          // escaped meta Characters: /\\+/ /\\[/\n          // or redundant escaping: /\\a/\n          // without the escaping \"\\\"\n          return regExpSource[1];\n        } else {\n          return options.useSticky ? addStickyFlag(currPattern) : addStartOfInput(currPattern);\n        }\n      } else if (isFunction(currPattern)) {\n        hasCustom = true;\n        // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n        return {\n          exec: currPattern\n        };\n      } else if (has(currPattern, \"exec\")) {\n        hasCustom = true;\n        // ICustomPattern\n        return currPattern;\n      } else if (typeof currPattern === \"string\") {\n        if (currPattern.length === 1) {\n          return currPattern;\n        } else {\n          var escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n          var wrappedRegExp = new RegExp(escapedRegExpString);\n          return options.useSticky ? addStickyFlag(wrappedRegExp) : addStartOfInput(wrappedRegExp);\n        }\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n  });\n  var patternIdxToType;\n  var patternIdxToGroup;\n  var patternIdxToLongerAltIdx;\n  var patternIdxToPushMode;\n  var patternIdxToPopMode;\n  tracer(\"misc mapping\", function () {\n    patternIdxToType = map(onlyRelevantTypes, function (currType) {\n      return currType.tokenTypeIdx;\n    });\n    patternIdxToGroup = map(onlyRelevantTypes, function (clazz) {\n      var groupName = clazz.GROUP;\n      /* istanbul ignore next */\n      if (groupName === Lexer.SKIPPED) {\n        return undefined;\n      } else if (isString(groupName)) {\n        return groupName;\n      } else if (isUndefined(groupName)) {\n        return false;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n    patternIdxToLongerAltIdx = map(onlyRelevantTypes, function (clazz) {\n      var longerAltType = clazz.LONGER_ALT;\n      if (longerAltType) {\n        var longerAltIdx = indexOf(onlyRelevantTypes, longerAltType);\n        return longerAltIdx;\n      }\n    });\n    patternIdxToPushMode = map(onlyRelevantTypes, function (clazz) {\n      return clazz.PUSH_MODE;\n    });\n    patternIdxToPopMode = map(onlyRelevantTypes, function (clazz) {\n      return has(clazz, \"POP_MODE\");\n    });\n  });\n  var patternIdxToCanLineTerminator;\n  tracer(\"Line Terminator Handling\", function () {\n    var lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n    patternIdxToCanLineTerminator = map(onlyRelevantTypes, function (tokType) {\n      return false;\n    });\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = map(onlyRelevantTypes, function (tokType) {\n        if (has(tokType, \"LINE_BREAKS\")) {\n          return tokType.LINE_BREAKS;\n        } else {\n          if (checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false) {\n            return canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n          }\n        }\n      });\n    }\n  });\n  var patternIdxToIsCustom;\n  var patternIdxToShort;\n  var emptyGroups;\n  var patternIdxToConfig;\n  tracer(\"Misc Mapping #2\", function () {\n    patternIdxToIsCustom = map(onlyRelevantTypes, isCustomPattern);\n    patternIdxToShort = map(allTransformedPatterns, isShortPattern);\n    emptyGroups = reduce(onlyRelevantTypes, function (acc, clazz) {\n      var groupName = clazz.GROUP;\n      if (isString(groupName) && !(groupName === Lexer.SKIPPED)) {\n        acc[groupName] = [];\n      }\n      return acc;\n    }, {});\n    patternIdxToConfig = map(allTransformedPatterns, function (x, idx) {\n      return {\n        pattern: allTransformedPatterns[idx],\n        longerAlt: patternIdxToLongerAltIdx[idx],\n        canLineTerminator: patternIdxToCanLineTerminator[idx],\n        isCustom: patternIdxToIsCustom[idx],\n        short: patternIdxToShort[idx],\n        group: patternIdxToGroup[idx],\n        push: patternIdxToPushMode[idx],\n        pop: patternIdxToPopMode[idx],\n        tokenTypeIdx: patternIdxToType[idx],\n        tokenType: onlyRelevantTypes[idx]\n      };\n    });\n  });\n  var canBeOptimized = true;\n  var charCodeToPatternIdxToConfig = [];\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", function () {\n      charCodeToPatternIdxToConfig = reduce(onlyRelevantTypes, function (result, currTokType, idx) {\n        if (typeof currTokType.PATTERN === \"string\") {\n          var charCode = currTokType.PATTERN.charCodeAt(0);\n          var optimizedIdx = charCodeToOptimizedIndex(charCode);\n          addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n        } else if (isArray(currTokType.START_CHARS_HINT)) {\n          var lastOptimizedIdx_1;\n          forEach(currTokType.START_CHARS_HINT, function (charOrInt) {\n            var charCode = typeof charOrInt === \"string\" ? charOrInt.charCodeAt(0) : charOrInt;\n            var currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n            // Avoid adding the config multiple times\n            if (lastOptimizedIdx_1 !== currOptimizedIdx) {\n              lastOptimizedIdx_1 = currOptimizedIdx;\n              addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n            }\n          });\n        } else if (isRegExp(currTokType.PATTERN)) {\n          if (currTokType.PATTERN.unicode) {\n            canBeOptimized = false;\n            if (options.ensureOptimizations) {\n              PRINT_ERROR(\"\" + failedOptimizationPrefixMsg + (\"\\tUnable to analyze < \" + currTokType.PATTERN.toString() + \" > pattern.\\n\") + \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tFor details See: https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\");\n            }\n          } else {\n            var optimizedCodes = getOptimizedStartCodesIndices(currTokType.PATTERN, options.ensureOptimizations);\n            /* istanbul ignore if */\n            // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n            // the first should be a different validation and the second cannot be tested.\n            if (isEmpty(optimizedCodes)) {\n              // we cannot understand what codes may start possible matches\n              // The optimization correctness requires knowing start codes for ALL patterns.\n              // Not actually sure this is an error, no debug message\n              canBeOptimized = false;\n            }\n            forEach(optimizedCodes, function (code) {\n              addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n            });\n          }\n        } else {\n          if (options.ensureOptimizations) {\n            PRINT_ERROR(\"\" + failedOptimizationPrefixMsg + (\"\\tTokenType: <\" + currTokType.name + \"> is using a custom token pattern without providing <start_chars_hint> parameter.\\n\") + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tFor details See: https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\");\n          }\n          canBeOptimized = false;\n        }\n        return result;\n      }, []);\n    });\n  }\n  tracer(\"ArrayPacking\", function () {\n    charCodeToPatternIdxToConfig = packArray(charCodeToPatternIdxToConfig);\n  });\n  return {\n    emptyGroups: emptyGroups,\n    patternIdxToConfig: patternIdxToConfig,\n    charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n    hasCustom: hasCustom,\n    canBeOptimized: canBeOptimized\n  };\n}\nexport function validatePatterns(tokenTypes, validModesNames) {\n  var errors = [];\n  var missingResult = findMissingPatterns(tokenTypes);\n  errors = errors.concat(missingResult.errors);\n  var invalidResult = findInvalidPatterns(missingResult.valid);\n  var validTokenTypes = invalidResult.valid;\n  errors = errors.concat(invalidResult.errors);\n  errors = errors.concat(validateRegExpPattern(validTokenTypes));\n  errors = errors.concat(findInvalidGroupType(validTokenTypes));\n  errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n  return errors;\n}\nfunction validateRegExpPattern(tokenTypes) {\n  var errors = [];\n  var withRegExpPatterns = filter(tokenTypes, function (currTokType) {\n    return isRegExp(currTokType[PATTERN]);\n  });\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n  return errors;\n}\nexport function findMissingPatterns(tokenTypes) {\n  var tokenTypesWithMissingPattern = filter(tokenTypes, function (currType) {\n    return !has(currType, PATTERN);\n  });\n  var errors = map(tokenTypesWithMissingPattern, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- missing static 'PATTERN' property\",\n      type: LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  var valid = difference(tokenTypes, tokenTypesWithMissingPattern);\n  return {\n    errors: errors,\n    valid: valid\n  };\n}\nexport function findInvalidPatterns(tokenTypes) {\n  var tokenTypesWithInvalidPattern = filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return !isRegExp(pattern) && !isFunction(pattern) && !has(pattern, \"exec\") && !isString(pattern);\n  });\n  var errors = map(tokenTypesWithInvalidPattern, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' can only be a RegExp, a\" + \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  var valid = difference(tokenTypes, tokenTypesWithInvalidPattern);\n  return {\n    errors: errors,\n    valid: valid\n  };\n}\nvar end_of_input = /[^\\\\][\\$]/;\nexport function findEndOfInputAnchor(tokenTypes) {\n  var EndAnchorFinder = /** @class */function (_super) {\n    __extends(EndAnchorFinder, _super);\n    function EndAnchorFinder() {\n      var _this = _super !== null && _super.apply(this, arguments) || this;\n      _this.found = false;\n      return _this;\n    }\n    EndAnchorFinder.prototype.visitEndAnchor = function (node) {\n      this.found = true;\n    };\n    return EndAnchorFinder;\n  }(BaseRegExpVisitor);\n  var invalidRegex = filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    try {\n      var regexpAst = getRegExpAst(pattern);\n      var endAnchorVisitor = new EndAnchorFinder();\n      endAnchorVisitor.visit(regexpAst);\n      return endAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return end_of_input.test(pattern.source);\n    }\n  });\n  var errors = map(invalidRegex, function (currType) {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\" + \"\\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" + \"\\tSee sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#ANCHORS\" + \"\\tfor details.\",\n      type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexport function findEmptyMatchRegExps(tokenTypes) {\n  var matchesEmptyString = filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return pattern.test(\"\");\n  });\n  var errors = map(matchesEmptyString, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' must not match an empty string\",\n      type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nvar start_of_input = /[^\\\\[][\\^]|^\\^/;\nexport function findStartOfInputAnchor(tokenTypes) {\n  var StartAnchorFinder = /** @class */function (_super) {\n    __extends(StartAnchorFinder, _super);\n    function StartAnchorFinder() {\n      var _this = _super !== null && _super.apply(this, arguments) || this;\n      _this.found = false;\n      return _this;\n    }\n    StartAnchorFinder.prototype.visitStartAnchor = function (node) {\n      this.found = true;\n    };\n    return StartAnchorFinder;\n  }(BaseRegExpVisitor);\n  var invalidRegex = filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    try {\n      var regexpAst = getRegExpAst(pattern);\n      var startAnchorVisitor = new StartAnchorFinder();\n      startAnchorVisitor.visit(regexpAst);\n      return startAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return start_of_input.test(pattern.source);\n    }\n  });\n  var errors = map(invalidRegex, function (currType) {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\" + \"\\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" + \"\\tSee https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#ANCHORS\" + \"\\tfor details.\",\n      type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexport function findUnsupportedFlags(tokenTypes) {\n  var invalidFlags = filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n  });\n  var errors = map(invalidFlags, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nexport function findDuplicatePatterns(tokenTypes) {\n  var found = [];\n  var identicalPatterns = map(tokenTypes, function (outerType) {\n    return reduce(tokenTypes, function (result, innerType) {\n      if (outerType.PATTERN.source === innerType.PATTERN.source && !contains(found, innerType) && innerType.PATTERN !== Lexer.NA) {\n        // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n        // in essence we are creating Equivalence classes on equality relation.\n        found.push(innerType);\n        result.push(innerType);\n        return result;\n      }\n      return result;\n    }, []);\n  });\n  identicalPatterns = compact(identicalPatterns);\n  var duplicatePatterns = filter(identicalPatterns, function (currIdenticalSet) {\n    return currIdenticalSet.length > 1;\n  });\n  var errors = map(duplicatePatterns, function (setOfIdentical) {\n    var tokenTypeNames = map(setOfIdentical, function (currType) {\n      return currType.name;\n    });\n    var dupPatternSrc = first(setOfIdentical).PATTERN;\n    return {\n      message: \"The same RegExp pattern ->\" + dupPatternSrc + \"<-\" + (\"has been used in all of the following Token Types: \" + tokenTypeNames.join(\", \") + \" <-\"),\n      type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical\n    };\n  });\n  return errors;\n}\nexport function findInvalidGroupType(tokenTypes) {\n  var invalidTypes = filter(tokenTypes, function (clazz) {\n    if (!has(clazz, \"GROUP\")) {\n      return false;\n    }\n    var group = clazz.GROUP;\n    return group !== Lexer.SKIPPED && group !== Lexer.NA && !isString(group);\n  });\n  var errors = map(invalidTypes, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexport function findModesThatDoNotExist(tokenTypes, validModes) {\n  var invalidModes = filter(tokenTypes, function (clazz) {\n    return clazz.PUSH_MODE !== undefined && !contains(validModes, clazz.PUSH_MODE);\n  });\n  var errors = map(invalidModes, function (tokType) {\n    var msg = \"Token Type: ->\" + tokType.name + \"<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->\" + tokType.PUSH_MODE + \"<-\" + \"which does not exist\";\n    return {\n      message: msg,\n      type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType]\n    };\n  });\n  return errors;\n}\nexport function findUnreachablePatterns(tokenTypes) {\n  var errors = [];\n  var canBeTested = reduce(tokenTypes, function (result, tokType, idx) {\n    var pattern = tokType.PATTERN;\n    if (pattern === Lexer.NA) {\n      return result;\n    }\n    // a more comprehensive validation for all forms of regExps would require\n    // deeper regExp analysis capabilities\n    if (isString(pattern)) {\n      result.push({\n        str: pattern,\n        idx: idx,\n        tokenType: tokType\n      });\n    } else if (isRegExp(pattern) && noMetaChar(pattern)) {\n      result.push({\n        str: pattern.source,\n        idx: idx,\n        tokenType: tokType\n      });\n    }\n    return result;\n  }, []);\n  forEach(tokenTypes, function (tokType, testIdx) {\n    forEach(canBeTested, function (_a) {\n      var str = _a.str,\n        idx = _a.idx,\n        tokenType = _a.tokenType;\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        var msg = \"Token: ->\" + tokenType.name + \"<- can never be matched.\\n\" + (\"Because it appears AFTER the Token Type ->\" + tokType.name + \"<-\") + \"in the lexer's definition.\\n\" + \"See https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#UNREACHABLE\";\n        errors.push({\n          message: msg,\n          type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType]\n        });\n      }\n    });\n  });\n  return errors;\n}\nfunction testTokenType(str, pattern) {\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    var regExpArray = pattern.exec(str);\n    return regExpArray !== null && regExpArray.index === 0;\n  } else if (isFunction(pattern)) {\n    // maintain the API of custom patterns\n    return pattern(str, 0, [], {});\n  } else if (has(pattern, \"exec\")) {\n    // maintain the API of custom patterns\n    return pattern.exec(str, 0, [], {});\n  } else if (typeof pattern === \"string\") {\n    return pattern === str;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\nfunction noMetaChar(regExp) {\n  //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n  var metaChars = [\".\", \"\\\\\", \"[\", \"]\", \"|\", \"^\", \"$\", \"(\", \")\", \"?\", \"*\", \"+\", \"{\"];\n  return find(metaChars, function (char) {\n    return regExp.source.indexOf(char) !== -1;\n  }) === undefined;\n}\nexport function addStartOfInput(pattern) {\n  var flags = pattern.ignoreCase ? \"i\" : \"\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(\"^(?:\" + pattern.source + \")\", flags);\n}\nexport function addStickyFlag(pattern) {\n  var flags = pattern.ignoreCase ? \"iy\" : \"y\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(\"\" + pattern.source, flags);\n}\nexport function performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  var errors = [];\n  // some run time checks to help the end users.\n  if (!has(lexerDefinition, DEFAULT_MODE)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + DEFAULT_MODE + \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n    });\n  }\n  if (!has(lexerDefinition, MODES)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + MODES + \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n    });\n  }\n  if (has(lexerDefinition, MODES) && has(lexerDefinition, DEFAULT_MODE) && !has(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized with a \" + DEFAULT_MODE + \": <\" + lexerDefinition.defaultMode + \">\" + \"which does not exist\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n    });\n  }\n  if (has(lexerDefinition, MODES)) {\n    forEach(lexerDefinition.modes, function (currModeValue, currModeName) {\n      forEach(currModeValue, function (currTokType, currIdx) {\n        if (isUndefined(currTokType)) {\n          errors.push({\n            message: \"A Lexer cannot be initialized using an undefined Token Type. Mode:\" + (\"<\" + currModeName + \"> at index: <\" + currIdx + \">\\n\"),\n            type: LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n          });\n        }\n      });\n    });\n  }\n  return errors;\n}\nexport function performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  var warnings = [];\n  var hasAnyLineBreak = false;\n  var allTokenTypes = compact(flatten(mapValues(lexerDefinition.modes, function (tokTypes) {\n    return tokTypes;\n  })));\n  var concreteTokenTypes = reject(allTokenTypes, function (currType) {\n    return currType[PATTERN] === Lexer.NA;\n  });\n  var terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n  if (trackLines) {\n    forEach(concreteTokenTypes, function (tokType) {\n      var currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n      if (currIssue !== false) {\n        var message = buildLineBreakIssueMessage(tokType, currIssue);\n        var warningDescriptor = {\n          message: message,\n          type: currIssue.issue,\n          tokenType: tokType\n        };\n        warnings.push(warningDescriptor);\n      } else {\n        // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n        if (has(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true;\n          }\n        } else {\n          if (canMatchCharCode(terminatorCharCodes, tokType.PATTERN)) {\n            hasAnyLineBreak = true;\n          }\n        }\n      }\n    });\n  }\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message: \"Warning: No LINE_BREAKS Found.\\n\" + \"\\tThis Lexer has been defined to track line and column information,\\n\" + \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" + \"\\tSee https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" + \"\\tfor details.\",\n      type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n    });\n  }\n  return warnings;\n}\nexport function cloneEmptyGroups(emptyGroups) {\n  var clonedResult = {};\n  var groupKeys = keys(emptyGroups);\n  forEach(groupKeys, function (currKey) {\n    var currGroupValue = emptyGroups[currKey];\n    /* istanbul ignore else */\n    if (isArray(currGroupValue)) {\n      clonedResult[currKey] = [];\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  });\n  return clonedResult;\n}\n// TODO: refactor to avoid duplication\nexport function isCustomPattern(tokenType) {\n  var pattern = tokenType.PATTERN;\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    return false;\n  } else if (isFunction(pattern)) {\n    // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n    return true;\n  } else if (has(pattern, \"exec\")) {\n    // ICustomPattern\n    return true;\n  } else if (isString(pattern)) {\n    return false;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\nexport function isShortPattern(pattern) {\n  if (isString(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0);\n  } else {\n    return false;\n  }\n}\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexport var LineTerminatorOptimizedTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: function (text) {\n    var len = text.length;\n    for (var i = this.lastIndex; i < len; i++) {\n      var c = text.charCodeAt(i);\n      if (c === 10) {\n        this.lastIndex = i + 1;\n        return true;\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2;\n        } else {\n          this.lastIndex = i + 1;\n        }\n        return true;\n      }\n    }\n    return false;\n  },\n  lastIndex: 0\n};\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n  if (has(tokType, \"LINE_BREAKS\")) {\n    // if the user explicitly declared the line_breaks option we will respect their choice\n    // and assume it is correct.\n    return false;\n  } else {\n    /* istanbul ignore else */\n    if (isRegExp(tokType.PATTERN)) {\n      try {\n        canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n      } catch (e) {\n        /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n        return {\n          issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: e.message\n        };\n      }\n      return false;\n    } else if (isString(tokType.PATTERN)) {\n      // string literal patterns can always be analyzed to detect line terminator usage\n      return false;\n    } else if (isCustomPattern(tokType)) {\n      // custom token types\n      return {\n        issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK\n      };\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n}\nexport function buildLineBreakIssueMessage(tokType, details) {\n  /* istanbul ignore else */\n  if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return \"Warning: unable to identify line terminator usage in pattern.\\n\" + (\"\\tThe problem is in the <\" + tokType.name + \"> Token Type\\n\") + (\"\\t Root cause: \" + details.errMsg + \".\\n\") + \"\\tFor details See: https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\";\n  } else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return \"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" + (\"\\tThe problem is in the <\" + tokType.name + \"> Token Type\\n\") + \"\\tFor details See: https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\";\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\nfunction getCharCodes(charsOrCodes) {\n  var charCodes = map(charsOrCodes, function (numOrString) {\n    if (isString(numOrString) && numOrString.length > 0) {\n      return numOrString.charCodeAt(0);\n    } else {\n      return numOrString;\n    }\n  });\n  return charCodes;\n}\nfunction addToMapOfArrays(map, key, value) {\n  if (map[key] === undefined) {\n    map[key] = [value];\n  } else {\n    map[key].push(value);\n  }\n}\nexport var minOptimizationVal = 256;\n/**\n * We ae mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nexport function charCodeToOptimizedIndex(charCode) {\n  return charCode < minOptimizationVal ? charCode : charCodeToOptimizedIdxMap[charCode];\n}\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nvar charCodeToOptimizedIdxMap = [];\nfunction initCharCodeToOptimizedIndexMap() {\n  if (isEmpty(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536);\n    for (var i = 0; i < 65536; i++) {\n      /* tslint:disable */\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n      /* tslint:enable */\n    }\n  }\n}\n//# sourceMappingURL=lexer.js.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}